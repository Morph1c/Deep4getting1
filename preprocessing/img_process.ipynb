{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "import os\n",
    "os.getcwd()\n",
    "os.chdir(\"/content/drive/MyDrive/Homework’s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "os.environ['MPLCONFIGDIR'] = os.getcwd()+'/configs/'\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=Warning)\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(seed)\n",
    "\n",
    "import logging\n",
    "\n",
    "import random\n",
    "random.seed(seed)\n",
    "\n",
    "# Import tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras as tfk\n",
    "from tensorflow.keras import layers as tfkl\n",
    "tf.autograph.set_verbosity(0)\n",
    "tf.get_logger().setLevel(logging.ERROR)\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "tf.random.set_seed(seed)\n",
    "tf.compat.v1.set_random_seed(seed)\n",
    "print(tf.__version__)\n",
    "\n",
    "# Import other libraries\n",
    "import cv2\n",
    "from tensorflow.keras.applications.mobilenet import preprocess_input\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#for gan...\n",
    "#!pip install visualkeras\n",
    "#import visualkeras\n",
    "\n",
    "#import imageio\n",
    "#from PIL import Image\n",
    "#from IPython.display import display\n",
    "#import seaborn as sns\n",
    "#import warnings\n",
    "#import logging\n",
    "\n",
    "#from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load images from the 'items/' folder\n",
    "temp = np.load('/content/drive/MyDrive/Homework’s/public_data.npz', allow_pickle = True)\n",
    "img = temp[\"data\"]\n",
    "label = temp[\"labels\"]\n",
    "  # Normalize image pixel values to a float range [0, 1]\n",
    "img = (img / 255).astype(np.float32)\n",
    "\n",
    "# set 0,1 label\n",
    "for i in range(len(label)):\n",
    "    if(label[i] == 'healthy'):\n",
    "        label[i] = 0\n",
    "    else:\n",
    "        label[i] = 1\n",
    "\n",
    "# cleaning images from trol and shrek\n",
    "ref_img = img[58]\n",
    "ref_img2 = img[2150]\n",
    "c = 0\n",
    "c2 = 0\n",
    "rm_indexes = []\n",
    "rm2_indexes = []\n",
    "for i in range(0, len(img)):\n",
    "    deviation = np.mean(np.abs(ref_img - img[i]))\n",
    "    deviation2 = np.mean(np.abs(ref_img2 - img[i]))\n",
    "    if(deviation == 0.0):\n",
    "        #print(i)\n",
    "        c += 1\n",
    "        rm_indexes.append(i)\n",
    "    elif(deviation2 == 0.0):\n",
    "        c2 += 1\n",
    "        rm2_indexes.append(i)\n",
    "\n",
    "clean_img = np.delete(img, rm_indexes + rm2_indexes, axis=0)\n",
    "clean_label = np.delete(label, rm_indexes + rm2_indexes, axis=0)\n",
    "print(clean_img.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "#directory for saved models\n",
    "saved_models_dir = \"\"\n",
    "#directory for checkpoints\n",
    "Checkpoints_dir  = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train - VAlidation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate 'animals' and 'items' arrays along axis 0\n",
    "X = clean_img\n",
    "# Create labels: 1 for 'animals', 0 for 'items'\n",
    "y = clean_label\n",
    "\n",
    "y = tfk.utils.to_categorical(y, 2) #one hot encodi\n",
    "\n",
    "# Split data into train_val and test sets\n",
    "#X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, random_state=seed, test_size=1000, stratify=np.argmax(y,axis=1))\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, random_state=seed, test_size=.15, stratify=np.argmax(y,axis=1))\n",
    "\n",
    "# Further split train_val into train and validation sets\n",
    "#X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, random_state=seed, test_size=1000, stratify=np.argmax(y_train_val,axis=1))\n",
    "\n",
    "# Print shapes of the datasets\n",
    "print(f\"X_train shape: {X_train.shape}, y_train shape: {y_train.shape}\")\n",
    "print(f\"X_val shape: {X_val.shape}, y_val shape: {y_val.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AUGMENTED TRAINING SET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# # train generator with augmentation\n",
    "train_image_gen  = ImageDataGenerator(rotation_range=40,\n",
    "                                      width_shift_range=0.2,\n",
    "                                      height_shift_range=0.2,\n",
    "                                      zoom_range=[0.5,1.5],\n",
    "                                      shear_range=0.2,\n",
    "                                      vertical_flip=True,\n",
    "                                      horizontal_flip=True,\n",
    "                                      fill_mode='reflect',\n",
    "                                      )\n",
    "\n",
    "# validation generator without augmentation\n",
    "\n",
    "train_dataset = train_image_gen.flow(x = X_train, y = y_train, seed = 42, batch_size = BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
