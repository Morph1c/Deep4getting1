{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Data and dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "os.environ['MPLCONFIGDIR'] = os.getcwd()+'/configs/'\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(seed)\n",
    "\n",
    "\n",
    "\n",
    "import random\n",
    "random.seed(seed)\n",
    "import logging\n",
    "# Import tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras as tfk\n",
    "from tensorflow.keras import layers\n",
    "tf.autograph.set_verbosity(0)\n",
    "tf.get_logger().setLevel(logging.ERROR)\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "tf.random.set_seed(seed)\n",
    "tf.compat.v1.set_random_seed(seed)\n",
    "print(tf.__version__)\n",
    "\n",
    "# Import other libraries\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#for gan...\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import copy\n",
    "def add_noise(cop):\n",
    "    imagee = copy.copy(cop)\n",
    "    var = random.randint(0, 1)\n",
    "    imagee = orthogonal_rot(imagee)\n",
    "    if var == 1:\n",
    "        '''Add random noise to an image'''\n",
    "        imagee = imagee/255\n",
    "        VARIABILITY = 0.01\n",
    "        deviation = VARIABILITY\n",
    "        noise = np.random.normal(0, deviation, imagee.shape)\n",
    "        imagee += noise\n",
    "        # np.clip(img, 0., 255.)\n",
    "        # return imagee*255\n",
    "    # else:\n",
    "        # imagee = imagee*255\n",
    "        # lista = [10, 20, 25, 30, 35]\n",
    "\n",
    "        # l = random.choice(lista)\n",
    "        # box = np.zeros(l**2).reshape(l, l)\n",
    "        # xx, yy = np.random.randint(0,95-l, size=2)\n",
    "        # for i in range(3):\n",
    "        #     imagee[xx:xx+l, yy:yy+l, i] = box\n",
    "\n",
    "        return imagee*255\n",
    "    else:\n",
    "        return imagee\n",
    "\n",
    "def orthogonal_rot(cop):\n",
    "    imagee = copy.copy(cop)\n",
    "    return np.rot90(imagee, np.random.choice([-1, 0, 1]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class for customed learning rate scheduler "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from tensorflow.keras.layers import Dense, Activation,Dropout,Conv2D, MaxPooling2D,BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam, Adamax\n",
    "from tensorflow.keras.metrics import categorical_crossentropy\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import backend as K\n",
    "class LR_ASK(tf.keras.callbacks.Callback):\n",
    "    def __init__ (self, model, epochs,  ask_epoch, dwell=True, factor=.75): # initialization of the callback\n",
    "        super(LR_ASK, self).__init__()\n",
    "        self.model=model\n",
    "        self.ask_epoch=ask_epoch\n",
    "        self.epochs=epochs\n",
    "        self.ask=True # if True query the user on a specified epoch\n",
    "        self.lowest_vloss=np.inf\n",
    "        self.lowest_aloss=np.inf\n",
    "        self.best_weights=self.model.get_weights() # set best weights to model's initial weights\n",
    "        self.best_epoch=1\n",
    "        self.plist=[]\n",
    "        self.alist=[]\n",
    "        self.dwell= dwell\n",
    "        self.factor=factor\n",
    "\n",
    "    def get_list(self): # define a function to return the list of % validation change\n",
    "        return self.plist, self.alist\n",
    "    def on_train_begin(self, logs=None): # this runs on the beginning of training\n",
    "        if self.ask_epoch == 0:\n",
    "            print('you set ask_epoch = 0, ask_epoch will be set to 1', flush=True)\n",
    "            self.ask_epoch=1\n",
    "        if self.ask_epoch >= self.epochs: # you are running for epochs but ask_epoch>epochs\n",
    "            print('ask_epoch >= epochs, will train for ', epochs, ' epochs', flush=True)\n",
    "            self.ask=False # do not query the user\n",
    "        if self.epochs == 1:\n",
    "            self.ask=False # running only for 1 epoch so do not query user\n",
    "        else:\n",
    "            msg =f'Training will proceed until epoch {ask_epoch} then you will be asked to'\n",
    "            print(msg )\n",
    "            msg='enter H to halt training or enter an integer for how many more epochs to run then be asked again'\n",
    "            print(msg)\n",
    "            if self.dwell:\n",
    "                msg='learning rate will be automatically adjusted during training'\n",
    "                print(msg, (0,255,0))\n",
    "        self.start_time= time.time() # set the time at which training started\n",
    "\n",
    "    def on_train_end(self, logs=None):   # runs at the end of training\n",
    "        msg=f'loading model with weights from epoch {self.best_epoch}'\n",
    "        print(msg)\n",
    "        model.set_weights(self.best_weights) # set the weights of the model to the best weights\n",
    "        tr_duration=time.time() - self.start_time   # determine how long the training cycle lasted\n",
    "        hours = tr_duration // 3600\n",
    "        minutes = (tr_duration - (hours * 3600)) // 60\n",
    "        seconds = tr_duration - ((hours * 3600) + (minutes * 60))\n",
    "        msg = f'training elapsed time was {str(hours)} hours, {minutes:4.1f} minutes, {seconds:4.2f} seconds)'\n",
    "        print (msg) # print out training duration time\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):  # method runs on the end of each epoch\n",
    "        vloss=logs.get('val_loss')  # get the validation loss for this epoch\n",
    "        aloss=logs.get('loss')\n",
    "        if epoch >0:\n",
    "            deltav = self.lowest_vloss- vloss\n",
    "            pimprov=(deltav/self.lowest_vloss) * 100\n",
    "            self.plist.append(pimprov)\n",
    "            deltaa=self.lowest_aloss-aloss\n",
    "            aimprov=(deltaa/self.lowest_aloss) * 100\n",
    "            self.alist.append(aimprov)\n",
    "        else:\n",
    "            pimprov=0.0\n",
    "            aimprov=0.0\n",
    "        if vloss< self.lowest_vloss:\n",
    "            self.lowest_vloss=vloss\n",
    "            self.best_weights=self.model.get_weights() # set best weights to model's initial weights\n",
    "            self.best_epoch=epoch + 1\n",
    "            msg=f'\\n validation loss of {vloss:7.4f} is {pimprov:7.4f} % below lowest loss, saving weights from epoch {str(epoch + 1):3s} as best weights'\n",
    "            print(msg) # green foreground\n",
    "        else: # validation loss increased\n",
    "            pimprov=abs(pimprov)\n",
    "            msg=f'\\n validation loss of {vloss:7.4f} is {pimprov:7.4f} % above lowest loss of {self.lowest_vloss:7.4f} keeping weights from epoch {str(self.best_epoch)} as best weights'\n",
    "            print(msg) # yellow foreground\n",
    "            if self.dwell: # if dwell is True when the validation loss increases the learning rate is automatically reduced and model weights are set to best weights\n",
    "                lr=float(tf.keras.backend.get_value(self.model.optimizer.lr)) # get the current learning rate\n",
    "                new_lr=lr * self.factor\n",
    "                msg=f'learning rate was automatically adjusted from {lr:8.6f} to {new_lr:8.6f}, model weights set to best weights'\n",
    "                print(msg) # cyan foreground\n",
    "                tf.keras.backend.set_value(self.model.optimizer.lr, new_lr) # set the learning rate in the optimizer\n",
    "                model.set_weights(self.best_weights) # set the weights of the model to the best weights\n",
    "\n",
    "        if aloss< self.lowest_aloss:\n",
    "            self.lowest_aloss=aloss\n",
    "        if self.ask: # are the conditions right to query the user?\n",
    "            if epoch + 1 ==self.ask_epoch: # is this epoch the one for quering the user?\n",
    "                msg='\\n Enter H to end training or  an integer for the number of additional epochs to run then ask again'\n",
    "                print(msg) # cyan foreground\n",
    "                ans=input()\n",
    "\n",
    "                if ans == 'H' or ans =='h' or ans == '0': # quit training for these conditions\n",
    "                    msg=f'you entered {ans},  Training halted on epoch {epoch+1} due to user input\\n'\n",
    "                    print(msg)\n",
    "                    self.model.stop_training = True # halt training\n",
    "                else: # user wants to continue training\n",
    "                    self.ask_epoch += int(ans)\n",
    "                    if self.ask_epoch > self.epochs:\n",
    "                        print('\\nYou specified maximum epochs of as ', self.epochs, ' cannot train for ', self.ask_epoch, flush =True)\n",
    "                    else:\n",
    "                        msg=f'you entered {ans} Training will continue to epoch {self.ask_epoch}'\n",
    "                        print(msg) # cyan foreground\n",
    "                        if self.dwell==False:\n",
    "                            lr=float(tf.keras.backend.get_value(self.model.optimizer.lr)) # get the current learning rate\n",
    "                            msg=f'current LR is  {lr:8.6f}  hit enter to keep  this LR or enter a new LR'\n",
    "                            print(msg) # cyan foreground\n",
    "                            ans=input(' ')\n",
    "                            if ans =='':\n",
    "                                msg=f'keeping current LR of {lr:7.5f}'\n",
    "                                print(msg) # cyan foreground\n",
    "                            else:\n",
    "                                new_lr=float(ans)\n",
    "                                tf.keras.backend.set_value(self.model.optimizer.lr, new_lr) # set the learning rate in the optimizer\n",
    "                                msg=f' changing LR to {ans}'\n",
    "                                print(msg) # cyan foreground"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loading and data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Load images from the 'items/' folder\n",
    "temp = np.load('/content/drive/MyDrive/Copia di public_data.npz', allow_pickle = True)\n",
    "img = temp[\"data\"]\n",
    "label = temp[\"labels\"]\n",
    "  # Normalize image pixel values to a float range [0, 1]\n",
    "img = (img).astype(np.float32)\n",
    "\n",
    "# set 0,1 label\n",
    "for i in range(len(label)):\n",
    "    if(label[i] == 'healthy'):\n",
    "        label[i] = 0\n",
    "    else:\n",
    "        label[i] = 1\n",
    "\n",
    "# cleaning images from trol and shrek\n",
    "ref_img = img[58]\n",
    "ref_img2 = img[2150]\n",
    "c = 0\n",
    "c2 = 0\n",
    "rm_indexes = []\n",
    "rm2_indexes = []\n",
    "for i in range(0, len(img)):\n",
    "    deviation = np.mean(np.abs(ref_img - img[i]))\n",
    "    deviation2 = np.mean(np.abs(ref_img2 - img[i]))\n",
    "    if(deviation == 0.0):\n",
    "        #print(i)\n",
    "        c += 1\n",
    "        rm_indexes.append(i)\n",
    "    elif(deviation2 == 0.0):\n",
    "        c2 += 1\n",
    "        rm2_indexes.append(i)\n",
    "\n",
    "clean_img = np.delete(img, rm_indexes + rm2_indexes, axis=0)\n",
    "clean_label = np.delete(label, rm_indexes + rm2_indexes, axis=0)\n",
    "\n",
    "\n",
    "#DATA AUGMENTATION TO BALANCE CLASSES!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "\n",
    "# Create an instance of ImageDataGenerator\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "#     shear_range=[0.3, 0.7],\n",
    "#     zoom_range=[0.3, 0.9],\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    # brightness_range=[0, 0.7],\n",
    "    fill_mode='reflect',\n",
    "    preprocessing_function = orthogonal_rot\n",
    ")\n",
    "\n",
    "# Reshape the numpy array to fit the requirements of the flow method\n",
    "x = clean_img[clean_label == 1]  # Replace 'your_numpy_array' with your actual numpy array\n",
    "\n",
    "# Create a generator to augment the images\n",
    "augmented_images = []\n",
    "for x_batch in datagen.flow(x, batch_size=1, seed=42, shuffle=False):\n",
    "    augmented_images.append(x_batch[0])\n",
    "    if len(augmented_images) >= 1198:\n",
    "        break\n",
    "\n",
    "# Convert the list of augmented images to a numpy array\n",
    "augmented_images_array = np.array(augmented_images)\n",
    "\n",
    "clean_img = np.append(clean_img, augmented_images_array, axis = 0)\n",
    "clean_label = np.append(clean_label, np.ones(1198))\n",
    "print(clean_img.shape)\n",
    "#!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "X = clean_img\n",
    "y = clean_label\n",
    "\n",
    "y = tfk.utils.to_categorical(y, 2) #one hot encodi\n",
    "\n",
    "# Split data into train_val and test sets\n",
    "#X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, random_state=seed, test_size=1000, stratify=np.argmax(y,axis=1))\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, random_state=seed, test_size=.15, stratify=np.argmax(y,axis=1))\n",
    "\n",
    "# Further split train_val into train and validation sets\n",
    "#X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, random_state=seed, test_size=1000, stratify=np.argmax(y_train_val,axis=1))\n",
    "\n",
    "# Print shapes of the datasets\n",
    "print(f\"X_train shape: {X_train.shape}, y_train shape: {y_train.shape}\")\n",
    "print(f\"X_val shape: {X_val.shape}, y_val shape: {y_val.shape}\")\n",
    "#print(f\"X_test shape: {X_test.shape}, y_test shape: {y_test.shape}\")\n",
    "\n",
    "\n",
    "######################OLD DATA AUGMENTATION -----way less efficient \n",
    "\n",
    "# BATCH_SIZE = 32\n",
    "# BATCH_SIZE = 32\n",
    "\n",
    "# from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# # # train generator with augmentation\n",
    "# train_image_gen  = ImageDataGenerator(rotation_range=20, #maybe better not to rotate??\n",
    "#                                       width_shift_range=0.1,\n",
    "#                                       height_shift_range=0.1,\n",
    "#                                       zoom_range=[0.5, 0.9],\n",
    "#                                       shear_range=0.2,\n",
    "#                                       brightness_range = [0.5, 1.5],\n",
    "#                                       # vertical_flip=True,\n",
    "#                                       # horizontal_flip=True,\n",
    "#                                       fill_mode='nearest',\n",
    "# #                                       validation_split = 0.15\n",
    "#                                       preprocessing_function=add_noise\n",
    "#                                       )\n",
    "\n",
    "\n",
    "# # validation generator without augmentation\n",
    "# # validation_image_gen = ImageDataGenerator(validation_split = 0.15,\n",
    "# #                                           )\n",
    "\n",
    "# train_dataset = train_image_gen.flow(x = X_train, y = y_train, seed = 42,\n",
    "#                                      batch_size = BATCH_SIZE)\n",
    "# validation_dataset = ImageDataGenerator().flow(X_val, y_val)\n",
    "\n",
    "##########################################################################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "del img, clean_img, clean_label, temp, x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data augmentations and train and validation tensors generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTO = tf.data.experimental.AUTOTUNE\n",
    "HEIGHT = 96\n",
    "WIDTH = 96\n",
    "\n",
    "yy_train = np.argmax(y_train, axis = -1)\n",
    "yy_val = np.argmax(y_val, axis = -1)\n",
    "train_tf = tf.data.Dataset.from_tensor_slices((X_train, yy_train.astype(int)))#remove astype(int) at the end\n",
    "validation_tf = tf.data.Dataset.from_tensor_slices((X_val, yy_val.astype(int)))\n",
    "\n",
    "IMG_SHAPE = 96\n",
    "BS = 128\n",
    "AUTO = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "# Referred from: https://arxiv.org/pdf/2002.05709.pdf (Appendxi A\n",
    "# corresponding GitHub: https://github.com/google-research/simclr/)\n",
    "# I did not use all the augmentation policies proposed in the above paper\n",
    "\n",
    "@tf.function\n",
    "def custom_augment(image, label):\n",
    "    # Random flips\n",
    "    image = random_apply(tf.image.flip_left_right, image, p=0.4)\n",
    "    image = random_apply(tf.image.flip_up_down, image, p = 0.2)\n",
    "    image = random_apply(tf.image.rot90, image, p = 0.1)\n",
    "#     image = random_apply(tf.image.random_crop()) #gotta resize\n",
    "#     image = random_apply(crop_and_resize, image, p = 0.2)\n",
    "    image = random_apply(cut_out, image, p = 0.8)\n",
    "    image = random_apply(aug_shear, image, p = 0.4)\n",
    "    image = random_apply(crop_img, image, p = 0.3)\n",
    "\n",
    "\n",
    "    # Randomly apply transformation (color distortions) with probability p.\n",
    "    image = random_apply(color_jitter, image, p=0.5)\n",
    "#     image = random_apply(color_drop, image, p=0.2)\n",
    "#     image = random_apply(cacca_su_img, image, p = 0.4)\n",
    "    image = random_apply(tf.image.transpose, image, p = 0.5)\n",
    "    return (image, label)\n",
    "\n",
    "@tf.function\n",
    "def color_jitter(x, s=0.3):\n",
    "    # one can also shuffle the order of following augmentations\n",
    "    # each time they are applied.\n",
    "    x = tf.image.random_brightness(x, max_delta=0.8*s)\n",
    "    x = tf.image.random_contrast(x, lower=1-0.8*s, upper=1+0.8*s)\n",
    "    x = tf.image.random_saturation(x, lower=1-0.5*s, upper=1+0.5*s)\n",
    "    x = tf.image.random_hue(x, max_delta=0.2*s)\n",
    "    x = tf.clip_by_value(x, 0, 1)\n",
    "    return x\n",
    "\n",
    "@tf.function\n",
    "def color_drop(x):\n",
    "    x = tf.image.rgb_to_grayscale(x)\n",
    "    x = tf.tile(x, [1, 1, 3])\n",
    "    return x\n",
    "\n",
    "@tf.function\n",
    "def cut_out(x):\n",
    "  return data_augment_cutout(x)\n",
    "\n",
    "def data_augment_cutout(image, min_mask_size=(int(HEIGHT * .1), int(HEIGHT * .1)),\n",
    "                        max_mask_size=(int(HEIGHT * .125), int(HEIGHT * .125))):\n",
    "    p_cutout = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n",
    "\n",
    "    if p_cutout > .85: # 10~15 cut outs\n",
    "        n_cutout = tf.random.uniform([], 10, 15, dtype=tf.int32)\n",
    "        image = random_cutout(image, HEIGHT, WIDTH,\n",
    "                              min_mask_size=min_mask_size, max_mask_size=max_mask_size, k=n_cutout)\n",
    "    elif p_cutout > .6: # 5~10 cut outs\n",
    "        n_cutout = tf.random.uniform([], 5, 10, dtype=tf.int32)\n",
    "        image = random_cutout(image, HEIGHT, WIDTH,\n",
    "                              min_mask_size=min_mask_size, max_mask_size=max_mask_size, k=n_cutout)\n",
    "    elif p_cutout > .25: # 2~5 cut outs\n",
    "        n_cutout = tf.random.uniform([], 2, 5, dtype=tf.int32)\n",
    "        image = random_cutout(image, HEIGHT, WIDTH,\n",
    "                              min_mask_size=min_mask_size, max_mask_size=max_mask_size, k=n_cutout)\n",
    "    else: # 1 cut out\n",
    "        image = random_cutout(image, HEIGHT, WIDTH,\n",
    "                              min_mask_size=min_mask_size, max_mask_size=max_mask_size, k=1)\n",
    "\n",
    "    return image\n",
    "def random_cutout(image, height, width, channels=3, min_mask_size=(10, 10), max_mask_size=(80, 80), k=1):\n",
    "    assert height > min_mask_size[0]\n",
    "    assert width > min_mask_size[1]\n",
    "    assert height > max_mask_size[0]\n",
    "    assert width > max_mask_size[1]\n",
    "    for i in range(k):\n",
    "      mask_height = tf.random.uniform(shape=[], minval=min_mask_size[0], maxval=max_mask_size[0], dtype=tf.int32)\n",
    "      mask_width = tf.random.uniform(shape=[], minval=min_mask_size[1], maxval=max_mask_size[1], dtype=tf.int32)\n",
    "\n",
    "      pad_h = height - mask_height\n",
    "      pad_top = tf.random.uniform(shape=[], minval=0, maxval=pad_h, dtype=tf.int32)\n",
    "      pad_bottom = pad_h - pad_top\n",
    "\n",
    "      pad_w = width - mask_width\n",
    "      pad_left = tf.random.uniform(shape=[], minval=0, maxval=pad_w, dtype=tf.int32)\n",
    "      pad_right = pad_w - pad_left\n",
    "\n",
    "      cutout_area = tf.zeros(shape=[mask_height, mask_width, channels], dtype=tf.uint8)\n",
    "\n",
    "      cutout_mask = tf.pad([cutout_area], [[0,0],[pad_top, pad_bottom], [pad_left, pad_right], [0,0]], constant_values=1)\n",
    "      cutout_mask = tf.squeeze(cutout_mask, axis=0)\n",
    "      image = tf.multiply(tf.cast(image, tf.float32), tf.cast(cutout_mask, tf.float32))\n",
    "\n",
    "    return image\n",
    "\n",
    "@tf.function\n",
    "def aug_shear(x):\n",
    "  p_shear = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n",
    "  if p_shear > .5:\n",
    "      x = transform_shear(x, HEIGHT, shear=20.)\n",
    "  else:\n",
    "      x = transform_shear(x, HEIGHT, shear=-20.)\n",
    "  return x\n",
    "\n",
    "def transform_shear(image, height, shear):\n",
    "    # input image - is one image of size [dim,dim,3] not a batch of [b,dim,dim,3]\n",
    "    # output - image randomly sheared\n",
    "    DIM = height\n",
    "    XDIM = DIM%2 #fix for size 331\n",
    "\n",
    "    shear = shear * tf.random.uniform([1],dtype='float32')\n",
    "    shear = math.pi * shear / 180.\n",
    "\n",
    "    # SHEAR MATRIX\n",
    "    one = tf.constant([1],dtype='float32')\n",
    "    zero = tf.constant([0],dtype='float32')\n",
    "    c2 = tf.math.cos(shear)\n",
    "    s2 = tf.math.sin(shear)\n",
    "    shear_matrix = tf.reshape(tf.concat([one,s2,zero, zero,c2,zero, zero,zero,one],axis=0),[3,3])\n",
    "\n",
    "    # LIST DESTINATION PIXEL INDICES\n",
    "    x = tf.repeat( tf.range(DIM//2,-DIM//2,-1), DIM )\n",
    "    y = tf.tile( tf.range(-DIM//2,DIM//2),[DIM] )\n",
    "    z = tf.ones([DIM*DIM],dtype='int32')\n",
    "    idx = tf.stack( [x,y,z] )\n",
    "\n",
    "    # ROTATE DESTINATION PIXELS ONTO ORIGIN PIXELS\n",
    "    idx2 = K.dot(shear_matrix,tf.cast(idx,dtype='float32'))\n",
    "    idx2 = K.cast(idx2,dtype='int32')\n",
    "    idx2 = K.clip(idx2,-DIM//2+XDIM+1,DIM//2)\n",
    "\n",
    "    # FIND ORIGIN PIXEL VALUES\n",
    "    idx3 = tf.stack( [DIM//2-idx2[0,], DIM//2-1+idx2[1,]] )\n",
    "    d = tf.gather_nd(image, tf.transpose(idx3))\n",
    "\n",
    "    return tf.reshape(d,[DIM,DIM,3])\n",
    "\n",
    "@tf.function\n",
    "def crop_img(x):\n",
    "  p_crop = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n",
    "  if p_crop > .6:\n",
    "    if p_crop > .85:\n",
    "        x = tf.image.central_crop(x, central_fraction=.7)\n",
    "    else:\n",
    "        x = tf.image.central_crop(x, central_fraction=.8)\n",
    "  else:\n",
    "    crop_size = tf.random.uniform([], int(HEIGHT*.6), HEIGHT, dtype=tf.int32)\n",
    "    x = tf.image.random_crop(x, size=[crop_size, crop_size, 3])\n",
    "  x = tf.image.resize(x, size=[HEIGHT, WIDTH])\n",
    "  return x\n",
    "\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def random_apply(func, x, p):\n",
    "    return tf.cond(\n",
    "        tf.less(tf.random.uniform([], minval=0, maxval=1, dtype=tf.float32),\n",
    "                tf.cast(p, tf.float32)),\n",
    "        lambda: func(x),\n",
    "        lambda: x)\n",
    "\n",
    "# # @tf.function\n",
    "# def cacca_su_img(imageee):\n",
    "#     imagee = 255*imageee.numpy()\n",
    "#     lista = [20, 25, 30, 35]\n",
    "#     l = random.choice(lista)\n",
    "#     box = np.zeros(l**2).reshape(l, l)\n",
    "#     xx, yy = np.random.randint(0,95-l, size=2)\n",
    "#     for i in range(3):\n",
    "#         imagee[xx:xx+l, yy:yy+l, i] = box\n",
    "\n",
    "#     imagee = tf.convert_to_tensor(imagee)\n",
    "\n",
    "#     return imagee/255\n",
    "\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def preprocess_image(image, label):\n",
    "  # image = image/255\n",
    "  image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "  #     image = tf.image.resize(image, (IMG_SHAPE, IMG_SHAPE))\n",
    "  image = image/255\n",
    "  return (image, label)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def preprocess_image_class(image, label):\n",
    "  image = image/255\n",
    "  label = tf.one_hot()\n",
    "  return (image, label)\n",
    "\n",
    "train_tf = (\n",
    "    train_tf\n",
    "    .map(preprocess_image, num_parallel_calls=AUTO)\n",
    "    .shuffle(100)\n",
    "    .map(custom_augment, num_parallel_calls=AUTO)\n",
    "    .batch(BS)\n",
    "    .prefetch(AUTO)\n",
    ")\n",
    "\n",
    "validation_tf = (\n",
    "    validation_tf\n",
    "    .map(preprocess_image, num_parallel_calls=AUTO)\n",
    "    .shuffle(100)\n",
    "    .batch(BS)#BS\n",
    "    .prefetch(AUTO)\n",
    ")\n",
    "#IF YOU WANT TO DO CLASSIFICATION AND NOT SUPERVISED CONTRASTIVE TRAINING, RUN THIS!\n",
    "# train_tf = (train_tf.map(lambda x, y: (x, tf.one_hot(y, depth =2)))) #let's go back to categorical values\n",
    "# validation_tf = (validation_tf.map(lambda x, y: (x, tf.one_hot(y, depth = 2))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#example of images augmented\n",
    "image_batch, label_batch = next(iter(train_tf))\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for n in range(25):\n",
    "    ax = plt.subplot(5, 5, n+1)\n",
    "    plt.imshow(image_batch[n])\n",
    "    plt.title(label_batch[n].numpy())\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised Contrastive Learning "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the encoder: EffnetV2L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SHAPE = 96\n",
    "class UnitNormLayer(tf.keras.layers.Layer):\n",
    "    '''Normalize vectors (euclidean norm) in batch to unit hypersphere.\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        super(UnitNormLayer, self).__init__()\n",
    "\n",
    "    def call(self, input_tensor):\n",
    "        norm = tf.norm(input_tensor, axis=1)\n",
    "        return input_tensor / tf.reshape(norm, [-1, 1])\n",
    "\n",
    "    # Encoder Network\n",
    "def encoder_net():\n",
    "  inputs = Input((IMG_SHAPE, IMG_SHAPE, 3))\n",
    "  normalization_layer = UnitNormLayer()\n",
    "\n",
    "  encoder = tf.keras.applications.EfficientNetV2L(\n",
    "    include_top=False,\n",
    "    weights=\"imagenet\",\n",
    "    input_tensor=None,\n",
    "    input_shape=(96, 96, 3),\n",
    "    pooling='max',\n",
    "    classes=1000,\n",
    "    classifier_activation=\"softmax\",\n",
    "    include_preprocessing=True,\n",
    "    )\n",
    " \n",
    "  embeddings = encoder(inputs, training=True)\n",
    "  # embeddings = GlobalAveragePooling2D()(embeddings)\n",
    "  norm_embeddings = normalization_layer(embeddings)\n",
    "\n",
    "  encoder_network = Model(inputs, norm_embeddings)\n",
    "\n",
    "  return encoder_network\n",
    "\n",
    "# Projector Network\n",
    "def projector_net():\n",
    "\tprojector = tf.keras.models.Sequential([\n",
    "\t\tDense(128, activation=\"relu\"),\n",
    "\t\tUnitNormLayer()\n",
    "\t])\n",
    "\n",
    "\treturn projector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decay_steps = 1000 #COSINE DECAYING LEARNING RATE SCHEDULING \n",
    "lr_decayed_fn = tf.keras.experimental.CosineDecay(\n",
    "    initial_learning_rate=0.001, decay_steps=decay_steps)\n",
    "optimizer = tf.keras.optimizers.Adam(lr_decayed_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_r = encoder_net()\n",
    "projector_z = projector_net()\n",
    "\n",
    "@tf.function\n",
    "def train_step(images, labels): #just for the single batch\n",
    "\twith tf.GradientTape() as tape: #starts a context for automatic differentiation\n",
    "        #it defines a block of operations to be recorded for AD.\n",
    "        #any operations performed on tensors  are recorded on the tape\n",
    "        #so the gradients can be computed wrto the recorded computations\n",
    "\t\tr = encoder_r(images, training=True)\n",
    "\t\tz = projector_z(r, training=True)\n",
    "\t\tloss = losses.max_margin_contrastive_loss(z, labels, metric='cosine')\n",
    "#         loss = losses.SupervisedContrastiveLoss(temperature)\n",
    "\n",
    "\tgradients = tape.gradient(loss,\n",
    "\t\tencoder_r.trainable_variables + projector_z.trainable_variables)\n",
    "\toptimizer.apply_gradients(zip(gradients,\n",
    "\t\tencoder_r.trainable_variables + projector_z.trainable_variables))\n",
    "\n",
    "\treturn loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 20\n",
    "LOG_EVERY = 2\n",
    "train_loss_results = []\n",
    "\n",
    "start = time.time()\n",
    "for epoch in tqdm(range(EPOCHS)):\n",
    "\tepoch_loss_avg = tf.keras.metrics.Mean()\n",
    "\n",
    "\tfor (images, labels) in train_tf:\n",
    "\t\tloss = train_step(images, labels)\n",
    "\t\tepoch_loss_avg.update_state(loss)#updates for every epoch (training set)\n",
    "\n",
    "\ttrain_loss_results.append(epoch_loss_avg.result())\n",
    "\n",
    "\tif epoch % LOG_EVERY == 0:\n",
    "\t\tprint(\"Epoch: {} Loss: {:.3f}\".format(epoch, epoch_loss_avg.result()))\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "with plt.xkcd():\n",
    "    plt.plot(train_loss_results)\n",
    "    plt.title(\"Supervised Contrastive Loss\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PLOT OF THE EMBEDDINGS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_reg_pred = []; embeddings = []\n",
    "true_labels = np.argmax(y, axis = -1)\n",
    "embeddings = projector_z.predict(encoder_r.predict(X))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.manifold import TSNE\n",
    "def visualize_embeddings(embeddings, labels, figsize=(8, 8)):\n",
    "    # Extract TSNE values from embeddings\n",
    "    embed2D = TSNE(n_components=2, n_jobs=-1, random_state=seed).fit_transform(embeddings)\n",
    "    embed2D_x = embed2D[:,0]\n",
    "    embed2D_y = embed2D[:,1]\n",
    "\n",
    "    # Create dataframe with labels and TSNE values\n",
    "    df_embed = pd.DataFrame({'labels': labels})\n",
    "    df_embed = df_embed.assign(x=embed2D_x, y=embed2D_y)\n",
    "    # df_embed.to_csv('/content/drive/MyDrive/embed_effnetv2L.csv', index=True)\n",
    "    # Create classes dataframes\n",
    "    df_embed_healthy = df_embed[df_embed['labels'] == 0]\n",
    "    df_embed_unhealthy = df_embed[df_embed['labels'] == 1]\n",
    "\n",
    "\n",
    "    # Plot embeddings\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.scatter(df_embed_healthy['x'], df_embed_healthy['y'],color='red',s=10,label='healthy')\n",
    "    plt.scatter(df_embed_unhealthy['x'], df_embed_unhealthy['y'],color='blue',s=10,label='unhealthy')\n",
    "\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "visualize_embeddings(embeddings, list(true_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CLASSIFICATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tf = (train_tf.map(lambda x, y: (x, tf.one_hot(y, depth =2)))) #let's go back to categorical values, CRUCIAL TO DO CLASSIFICATION \n",
    "validation_tf = (validation_tf.map(lambda x, y: (x, tf.one_hot(y, depth = 2))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SHAPE = 96\n",
    "def supervised_model():\n",
    "    inputs = Input((IMG_SHAPE, IMG_SHAPE, 3))\n",
    "    encoder_r.trainable = False\n",
    "\n",
    "    r = encoder_r(inputs, training=False)\n",
    "    # x = layers.GlobalAveragePooling2D(name = \"gap\")(x)\n",
    "    x=BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, name = \"batch\")(r)\n",
    "\n",
    "\n",
    "    x = layers.Dense(256,activation='relu')(x)\n",
    "    x = layers.Dense(256, kernel_initializer=tf.keras.initializers.HeUniform(seed=42))(x)\n",
    "    x = layers.BatchNormalization(name = \"batch2\")(x)\n",
    "    x = layers.Dropout(0.2, seed = 42, name = \"dropout\")(x)\n",
    "\n",
    "    x = layers.Dense(256, kernel_regularizer = regularizers.l2(l = 0.016),activity_regularizer=regularizers.l1(0.006),\n",
    "                        bias_regularizer=regularizers.l1(0.006) ,activation='relu')(x)\n",
    "    x = layers.BatchNormalization(name = \"batch3\")(x)\n",
    "    x = layers.Dropout(0.3, seed = 42, name = \"dropout2\")(x)\n",
    "\n",
    "    x = layers.Dense(128, activation = \"relu\", name = \"last_dense\")(x)\n",
    "    x = layers.BatchNormalization(name = \"batch4\")(x)\n",
    "    x = layers.Dropout(0.3, seed = 42, name = \"dropout3\")(x)\n",
    "\n",
    "    outputs = Dense(2, activation = \"softmax\")(x)\n",
    "\n",
    "\n",
    "\n",
    "    supervised_model = Model(inputs, outputs)\n",
    "\n",
    "    return supervised_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "model = supervised_model()\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "  # loss = 'binary_crossentropy',\n",
    "\tloss=tfk.losses.CategoricalCrossentropy(),\n",
    "\tmetrics=[\"accuracy\"])\n",
    "\n",
    "es = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10,\n",
    "\trestore_best_weights=True, verbose=1)\n",
    "\n",
    "model.summary()\n",
    "\n",
    "\n",
    "epochs=100\n",
    "ask_epoch=30\n",
    "ask=LR_ASK(model, epochs,  ask_epoch, factor = 0.8) #FACTOR MEASURES BY HOW MUCH WE DECREASE THE LEARNING RATE\n",
    "callbacks=[ask]\n",
    "\n",
    "history=model.fit(x=train_tf,  epochs=epochs, verbose=1, callbacks=callbacks,  validation_data=validation_tf,\n",
    "               validation_steps=None,  shuffle=False,  initial_epoch=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRANSFER LEARNING AND FINE TUINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RUN IF NOT RUN BEFORE: puts predictions back in one hot encoding format\n",
    "# train_tf = (train_tf.map(lambda x, y: (x, tf.one_hot(y, depth =2)))) #let's go back to categorical values\n",
    "# validation_tf = (validation_tf.map(lambda x, y: (x, tf.one_hot(y, depth = 2))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "convlarge = tf.keras.applications.ConvNeXtBase( #here just change with other models from keras.applications\n",
    "    include_top=False,\n",
    "    include_preprocessing=True,\n",
    "    weights=\"imagenet\",\n",
    "    input_tensor=None,\n",
    "    input_shape= (96,96, 3),\n",
    "    pooling=\"max\",\n",
    "    classes=2,\n",
    "    classifier_activation=\"softmax\",\n",
    ")\n",
    "\n",
    "convlarge.trainable = False\n",
    "\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "# Build the neural network layer by layer\n",
    "inputs = tfkl.Input(shape=(96, 96, 3))\n",
    "\n",
    "# x = img_augmentation(inputs)\n",
    "x = convlarge(inputs*255) #iamges in train_tf \n",
    "# x = layers.GlobalAveragePooling2D(name = \"gap\")(x)\n",
    "x=BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, name = \"batch\")(x)\n",
    "\n",
    "\n",
    "x = layers.Dense(256, kernel_regularizer = regularizers.l2(l = 0.016),activity_regularizer=regularizers.l1(0.006),\n",
    "                    bias_regularizer=regularizers.l1(0.006) ,activation='relu')(x)\n",
    "# x = layers.Dense(256, kernel_initializer=tf.keras.initializers.HeUniform(seed=42))(x)\n",
    "x = layers.BatchNormalization(name = \"batch2\")(x)\n",
    "x = layers.Dropout(0.3, seed = 42, name = \"dropout\")(x)\n",
    "\n",
    "x = layers.Dense(128, kernel_regularizer = regularizers.l2(l = 0.016),activity_regularizer=regularizers.l1(0.006),\n",
    "                    bias_regularizer=regularizers.l1(0.006) ,activation='relu')(x)\n",
    "x = layers.BatchNormalization(name = \"batch3\")(x)\n",
    "x = layers.Dropout(0.3, seed = 42, name = \"dropout2\")(x)\n",
    "\n",
    "outputs = tfkl.Dense(units=2, activation='softmax',name='Output2')(x)  #you cannnot use softmax with only one neuron since it normalizes over the output neurons\n",
    "model = tfk.Model(inputs, outputs)\n",
    "model.compile(loss=tfk.losses.CategoricalCrossentropy(), optimizer=tfk.optimizers.Adamax(learning_rate=0.01), metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=100\n",
    "ask_epoch=20 \n",
    "ask=LR_ASK(model, epochs,  ask_epoch)\n",
    "callbacks=[ask]\n",
    "\n",
    "history=model.fit(x=train_dataset,  epochs=epochs, verbose=1, callbacks=callbacks,  validation_data=validation_dataset,\n",
    "               validation_steps=None,  shuffle=False,  initial_epoch=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine Tuning procedure\n",
    "$32layers \\rightarrow 64layers \\rightarrow 96layers \\rightarrow allLayers$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "unfreeze = 32 #change it as you go on with the procedure. Go lower if 32 is already too much\n",
    "\n",
    "model.get_layer('convnext_base').trainable = True\n",
    "for i, layer in enumerate(model.get_layer('convnext_base').layers[:-unfreeze]):\n",
    "    layer.trainable = False\n",
    "\n",
    "# make sure BatchNorm layers are frozen\n",
    "for i, layer in enumerate(model.get_layer('convnext_base').layers):\n",
    "    if isinstance(layer, layers.BatchNormalization):\n",
    "        layer.trainable = False\n",
    "\n",
    "model.compile(loss=tfk.losses.CategoricalCrossentropy(), optimizer=tfk.optimizers.Adamax(0.0001), metrics=['accuracy'])\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=100\n",
    "ask_epoch=10\n",
    "ask=LR_ASK(model, epochs,  ask_epoch, factor = 0.55)\n",
    "callbacks=[ask]\n",
    "history=model.fit(x=train_dataset,  epochs=epochs, verbose=1, callbacks=callbacks,  validation_data=validation_dataset,\n",
    "                validation_steps=None,  shuffle=False,  initial_epoch=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RUN IF NOT RUN BEFORE: puts predictions back in one hot encoding format\n",
    "# train_tf = (train_tf.map(lambda x, y: (x, tf.one_hot(y, depth =2)))) #let's go back to categorical values\n",
    "# validation_tf = (validation_tf.map(lambda x, y: (x, tf.one_hot(y, depth = 2))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_conv = tfk.models.load_model('/content/drive/MyDrive/Homework’s/models/tensor_conv_base_full3')\n",
    "model_SCL = tfk.models.load_model('/content/drive/MyDrive/Homework’s/models/essnetv2L_more_augmentation')\n",
    "model_small = tfk.models.load_model('/content/drive/MyDrive/Homework’s/models/conv_small_64')\n",
    "\n",
    "model_conv._name = 'model_conv'\n",
    "model_SCL._name = 'model_SCL'\n",
    "model_small._name = 'model_small'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Layer, Concatenate\n",
    "def weight_init(shape =(1,1,2), weights=[1, 1, 1.5], dtype=tf.float32): #convnest_small has more weight (found to give better results)\n",
    "    return tf.constant(np.array(weights).reshape(shape), dtype=dtype)\n",
    "\n",
    "class WeightedAverage(Layer):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(WeightedAverage, self).__init__()\n",
    "\n",
    "    def build(self, input_shape):\n",
    "\n",
    "        self.W = self.add_weight(\n",
    "                    shape=(1,1,len(input_shape)),\n",
    "                    initializer=weight_init,\n",
    "                    dtype=tf.float32,\n",
    "                    trainable=True, name = 'cacca')\n",
    "    def call(self, inputs):\n",
    "\n",
    "        inputs = [tf.expand_dims(i, -1) for i in inputs]\n",
    "        inputs = Concatenate(axis=-1)(inputs)\n",
    "        weights = tf.nn.softmax(self.W, axis=-1)\n",
    "\n",
    "        return tf.reduce_mean(weights*inputs, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Layer, Concatenate\n",
    "models = [model_conv, model_SCL, model_small]\n",
    "\n",
    "inputs = tfk.Input(shape=(96, 96, 3))\n",
    "outputs = [model(inputs) for model in models]\n",
    "outputs_ensemble = WeightedAverage()(outputs)\n",
    "model_ensemble = tfk.Model(inputs=inputs, outputs=outputs_ensemble, name='ensemble_base_large')\n",
    "\n",
    "model_ensemble.compile(loss=tfk.losses.CategoricalCrossentropy(), optimizer=tfk.optimizers.Adamax(learning_rate=0.01), metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN with CBAM Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import GlobalAveragePooling2D, GlobalMaxPooling2D, Reshape, Dense, multiply, Permute, Concatenate, Conv2D, Add, Activation, Lambda\n",
    "from keras import backend as K\n",
    "from keras.activations import sigmoid\n",
    "from keras import layers\n",
    "from keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "from keras import initializers\n",
    "from keras.models import Sequential\n",
    "def cbam_block(cbam_feature, ratio=8):\n",
    "    \"\"\"Contains the implementation of Convolutional Block Attention Module(CBAM) block.\n",
    "    As described in https://arxiv.org/abs/1807.06521.\n",
    "    \"\"\"\n",
    "\n",
    "    cbam_feature = channel_attention(cbam_feature, ratio)\n",
    "    cbam_feature = spatial_attention(cbam_feature)\n",
    "    return cbam_feature\n",
    "\n",
    "def channel_attention(input_feature, ratio=8):\n",
    "\n",
    "    channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n",
    "    channel = input_feature.shape[channel_axis]\n",
    "\n",
    "    shared_layer_one = Dense(channel//ratio,\n",
    "                             activation='relu',\n",
    "                             kernel_initializer='he_normal',\n",
    "                             use_bias=True,\n",
    "                             bias_initializer='zeros')\n",
    "    shared_layer_two = Dense(channel,\n",
    "                             kernel_initializer='he_normal',\n",
    "                             use_bias=True,\n",
    "                             bias_initializer='zeros')\n",
    "\n",
    "    avg_pool = GlobalAveragePooling2D()(input_feature)\n",
    "    avg_pool = Reshape((1,1,channel))(avg_pool)\n",
    "    assert avg_pool.shape[1:] == (1,1,channel)\n",
    "    avg_pool = shared_layer_one(avg_pool)\n",
    "    assert avg_pool.shape[1:] == (1,1,channel//ratio)\n",
    "    avg_pool = shared_layer_two(avg_pool)\n",
    "    assert avg_pool.shape[1:] == (1,1,channel)\n",
    "\n",
    "    max_pool = GlobalMaxPooling2D()(input_feature)\n",
    "    max_pool = Reshape((1,1,channel))(max_pool)\n",
    "    assert max_pool.shape[1:] == (1,1,channel)\n",
    "    max_pool = shared_layer_one(max_pool)\n",
    "    assert max_pool.shape[1:] == (1,1,channel//ratio)\n",
    "    max_pool = shared_layer_two(max_pool)\n",
    "    assert max_pool.shape[1:] == (1,1,channel)\n",
    "\n",
    "    cbam_feature = Add()([avg_pool,max_pool])\n",
    "    cbam_feature = Activation('sigmoid')(cbam_feature)\n",
    "\n",
    "    if K.image_data_format() == \"channels_first\":\n",
    "        cbam_feature = Permute((3, 1, 2))(cbam_feature)\n",
    "\n",
    "    return multiply([input_feature, cbam_feature])\n",
    "\n",
    "def spatial_attention(input_feature):\n",
    "    kernel_size = 7\n",
    "\n",
    "    if K.image_data_format() == \"channels_first\":\n",
    "        channel = input_feature.shape[1]\n",
    "        cbam_feature = Permute((2,3,1))(input_feature)\n",
    "    else:\n",
    "        channel = input_feature.shape[-1]\n",
    "        cbam_feature = input_feature\n",
    "\n",
    "    avg_pool = Lambda(lambda x: K.mean(x, axis=3, keepdims=True))(cbam_feature)\n",
    "    assert avg_pool.shape[-1] == 1\n",
    "    max_pool = Lambda(lambda x: K.max(x, axis=3, keepdims=True))(cbam_feature)\n",
    "    assert max_pool.shape[-1] == 1\n",
    "    concat = Concatenate(axis=3)([avg_pool, max_pool])\n",
    "    assert concat.shape[-1] == 2\n",
    "    cbam_feature = Conv2D(filters = 1,\n",
    "                    kernel_size=kernel_size,\n",
    "                    strides=1,\n",
    "                    padding='same',\n",
    "                    activation='sigmoid',\n",
    "                    kernel_initializer='he_normal',\n",
    "                    use_bias=False)(concat)\n",
    "    assert cbam_feature.shape[-1] == 1\n",
    "\n",
    "    if K.image_data_format() == \"channels_first\":\n",
    "        cbam_feature = Permute((3, 1, 2))(cbam_feature)\n",
    "\n",
    "    return multiply([input_feature, cbam_feature])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batches = train_dataset\n",
    "validation_batches = validation_dataset\n",
    "IMG_SIZE = 96\n",
    "n_classes = 2\n",
    "EPOCHS = 50\n",
    "BATCH_SIZE = 8\n",
    "IMG_SIZE = 224\n",
    "n_classes = 4\n",
    "METRICS = [tfk.metrics.CategoricalAccuracy(name='accuracy'),\n",
    "           tfk.metrics.Precision(name='precision'),\n",
    "           tfk.metrics.Recall(name='recall'),\n",
    "           tfk.metrics.AUC(name='auc')]\n",
    "\n",
    "inp = layers.Input(shape=(IMG_SIZE,IMG_SIZE,3))\n",
    "x1 = layers.Resizing(IMG_SIZE, IMG_SIZE)(inp)\n",
    "# x2 = layers.Rescaling(1./255)(x1)\n",
    "x3 = layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu',\n",
    "                   padding = 'same', input_shape=(IMG_SIZE,IMG_SIZE,3))(x1)\n",
    "x4 = cbam_block(x3)\n",
    "x5 = layers.BatchNormalization(axis=-1)(x4)\n",
    "x6 = layers.MaxPool2D(pool_size=(2, 2))(x5)\n",
    "x7 = layers.Conv2D(filters=64, kernel_size=(3, 3),\n",
    "                   activation='relu', padding = 'same')(x6)\n",
    "x8 = cbam_block(x7)\n",
    "x9 = layers.BatchNormalization(axis=-1)(x8)\n",
    "x10 = layers.MaxPool2D(pool_size=(2, 2))(x9)\n",
    "x11 = layers.Conv2D(filters=128, kernel_size=(3, 3),\n",
    "                    activation='relu', padding = 'same')(x10)\n",
    "x12 = cbam_block(x11)\n",
    "x13 = layers.BatchNormalization(axis=-1)(x12)\n",
    "x14 = layers.MaxPool2D(pool_size=(2, 2))(x13)\n",
    "x15 = layers.Conv2D(filters=256, kernel_size=(3, 3),\n",
    "                      activation='relu', padding = 'same')(x14)\n",
    "x16 = cbam_block(x15)\n",
    "x17 = layers.BatchNormalization(axis=-1)(x16)\n",
    "x18 = layers.MaxPool2D(pool_size=(2, 2))(x17)\n",
    "y1 = layers.Flatten()(x18)\n",
    "y2 = layers.Dense(300, activation='relu')(y1)\n",
    "y3 = layers.Dense(150, activation='relu')(y2)\n",
    "y4 = layers.Dropout(0.25)(y3)\n",
    "y = layers.Dense(n_classes, activation='softmax')(y4)\n",
    "\n",
    "\n",
    "model = tf.keras.Model(inp, y)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "                   loss='categorical_crossentropy',\n",
    "                   metrics=METRICS)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=100\n",
    "ask_epoch=10\n",
    "ask=LR_ASK(model, epochs,  ask_epoch, factor = 0.65)\n",
    "callbacks=[ask]\n",
    "history=model.fit(x=train_dataset,  epochs=epochs, verbose=1, callbacks=callbacks,  validation_data=validation_dataset,\n",
    "               validation_steps=None,  shuffle=False,  initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
