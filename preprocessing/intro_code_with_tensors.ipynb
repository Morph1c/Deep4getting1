{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "os.environ['MPLCONFIGDIR'] = os.getcwd()+'/configs/'\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=Warning)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(seed)\n",
    "\n",
    "import logging\n",
    "\n",
    "import random\n",
    "random.seed(seed)\n",
    "\n",
    "# Import tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras as tfk\n",
    "from tensorflow.keras import layers as tfkl\n",
    "tf.autograph.set_verbosity(0)\n",
    "tf.get_logger().setLevel(logging.ERROR)\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "tf.random.set_seed(seed)\n",
    "tf.compat.v1.set_random_seed(seed)\n",
    "print(tf.__version__)\n",
    "\n",
    "# Import other libraries\n",
    "import cv2\n",
    "from tensorflow.keras.applications.mobilenet import preprocess_input\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import copy\n",
    "\n",
    "#functions\n",
    "def add_noise(cop):\n",
    "    imagee = copy.copy(cop)\n",
    "    var = random.randint(0, 1)\n",
    "    if var == 1:\n",
    "        '''Add random noise to an image'''\n",
    "        imagee = imagee/255\n",
    "        VARIABILITY = 0.02\n",
    "        deviation = VARIABILITY\n",
    "        noise = np.random.normal(0, deviation, imagee.shape)\n",
    "        imagee += noise\n",
    "        # np.clip(img, 0., 255.)\n",
    "        # return imagee*255\n",
    "    # else:\n",
    "        imagee = imagee*255\n",
    "        lista = [10, 20, 25, 30, 35]\n",
    "\n",
    "        l = random.choice(lista)\n",
    "        box = np.zeros(l**2).reshape(l, l)\n",
    "        xx, yy = np.random.randint(0,95-l, size=2)\n",
    "        for i in range(3):\n",
    "            imagee[xx:xx+l, yy:yy+l, i] = box\n",
    "\n",
    "        return imagee\n",
    "    else:\n",
    "        return imagee\n",
    "\n",
    "def orthogonal_rot(cop):\n",
    "    imagee = copy.copy(cop)\n",
    "    return np.rot90(imagee, np.random.choice([-1, 0, 1]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from tensorflow.keras.layers import Dense, Activation,Dropout,Conv2D, MaxPooling2D,BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam, Adamax\n",
    "from tensorflow.keras.metrics import categorical_crossentropy\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import backend as K\n",
    "class LR_ASK(tf.keras.callbacks.Callback):\n",
    "    def __init__ (self, model, epochs,  ask_epoch, dwell=True, factor=.75): # initialization of the callback\n",
    "        super(LR_ASK, self).__init__()\n",
    "        self.model=model\n",
    "        self.ask_epoch=ask_epoch\n",
    "        self.epochs=epochs\n",
    "        self.ask=True # if True query the user on a specified epoch\n",
    "        self.lowest_vloss=np.inf\n",
    "        self.lowest_aloss=np.inf\n",
    "        self.best_weights=self.model.get_weights() # set best weights to model's initial weights\n",
    "        self.best_epoch=1\n",
    "        self.plist=[]\n",
    "        self.alist=[]\n",
    "        self.dwell= dwell\n",
    "        self.factor=factor\n",
    "\n",
    "    def get_list(self): # define a function to return the list of % validation change\n",
    "        return self.plist, self.alist\n",
    "    def on_train_begin(self, logs=None): # this runs on the beginning of training\n",
    "        if self.ask_epoch == 0:\n",
    "            print('you set ask_epoch = 0, ask_epoch will be set to 1', flush=True)\n",
    "            self.ask_epoch=1\n",
    "        if self.ask_epoch >= self.epochs: # you are running for epochs but ask_epoch>epochs\n",
    "            print('ask_epoch >= epochs, will train for ', epochs, ' epochs', flush=True)\n",
    "            self.ask=False # do not query the user\n",
    "        if self.epochs == 1:\n",
    "            self.ask=False # running only for 1 epoch so do not query user\n",
    "        else:\n",
    "            msg =f'Training will proceed until epoch {ask_epoch} then you will be asked to'\n",
    "            print(msg )\n",
    "            msg='enter H to halt training or enter an integer for how many more epochs to run then be asked again'\n",
    "            print(msg)\n",
    "            if self.dwell:\n",
    "                msg='learning rate will be automatically adjusted during training'\n",
    "                print(msg, (0,255,0))\n",
    "        self.start_time= time.time() # set the time at which training started\n",
    "\n",
    "    def on_train_end(self, logs=None):   # runs at the end of training\n",
    "        msg=f'loading model with weights from epoch {self.best_epoch}'\n",
    "        print(msg)\n",
    "        model.set_weights(self.best_weights) # set the weights of the model to the best weights\n",
    "        tr_duration=time.time() - self.start_time   # determine how long the training cycle lasted\n",
    "        hours = tr_duration // 3600\n",
    "        minutes = (tr_duration - (hours * 3600)) // 60\n",
    "        seconds = tr_duration - ((hours * 3600) + (minutes * 60))\n",
    "        msg = f'training elapsed time was {str(hours)} hours, {minutes:4.1f} minutes, {seconds:4.2f} seconds)'\n",
    "        print (msg) # print out training duration time\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):  # method runs on the end of each epoch\n",
    "        vloss=logs.get('val_loss')  # get the validation loss for this epoch\n",
    "        aloss=logs.get('loss')\n",
    "        if epoch >0:\n",
    "            deltav = self.lowest_vloss- vloss\n",
    "            pimprov=(deltav/self.lowest_vloss) * 100\n",
    "            self.plist.append(pimprov)\n",
    "            deltaa=self.lowest_aloss-aloss\n",
    "            aimprov=(deltaa/self.lowest_aloss) * 100\n",
    "            self.alist.append(aimprov)\n",
    "        else:\n",
    "            pimprov=0.0\n",
    "            aimprov=0.0\n",
    "        if vloss< self.lowest_vloss:\n",
    "            self.lowest_vloss=vloss\n",
    "            self.best_weights=self.model.get_weights() # set best weights to model's initial weights\n",
    "            self.best_epoch=epoch + 1\n",
    "            msg=f'\\n validation loss of {vloss:7.4f} is {pimprov:7.4f} % below lowest loss, saving weights from epoch {str(epoch + 1):3s} as best weights'\n",
    "            print(msg) # green foreground\n",
    "        else: # validation loss increased\n",
    "            pimprov=abs(pimprov)\n",
    "            msg=f'\\n validation loss of {vloss:7.4f} is {pimprov:7.4f} % above lowest loss of {self.lowest_vloss:7.4f} keeping weights from epoch {str(self.best_epoch)} as best weights'\n",
    "            print(msg) # yellow foreground\n",
    "            if self.dwell: # if dwell is True when the validation loss increases the learning rate is automatically reduced and model weights are set to best weights\n",
    "                lr=float(tf.keras.backend.get_value(self.model.optimizer.lr)) # get the current learning rate\n",
    "                new_lr=lr * self.factor\n",
    "                msg=f'learning rate was automatically adjusted from {lr:8.6f} to {new_lr:8.6f}, model weights set to best weights'\n",
    "                print(msg) # cyan foreground\n",
    "                tf.keras.backend.set_value(self.model.optimizer.lr, new_lr) # set the learning rate in the optimizer\n",
    "                model.set_weights(self.best_weights) # set the weights of the model to the best weights\n",
    "\n",
    "        if aloss< self.lowest_aloss:\n",
    "            self.lowest_aloss=aloss\n",
    "        if self.ask: # are the conditions right to query the user?\n",
    "            if epoch + 1 ==self.ask_epoch: # is this epoch the one for quering the user?\n",
    "                msg='\\n Enter H to end training or  an integer for the number of additional epochs to run then ask again'\n",
    "                print(msg) # cyan foreground\n",
    "                ans=input()\n",
    "\n",
    "                if ans == 'H' or ans =='h' or ans == '0': # quit training for these conditions\n",
    "                    msg=f'you entered {ans},  Training halted on epoch {epoch+1} due to user input\\n'\n",
    "                    print(msg)\n",
    "                    self.model.stop_training = True # halt training\n",
    "                else: # user wants to continue training\n",
    "                    self.ask_epoch += int(ans)\n",
    "                    if self.ask_epoch > self.epochs:\n",
    "                        print('\\nYou specified maximum epochs of as ', self.epochs, ' cannot train for ', self.ask_epoch, flush =True)\n",
    "                    else:\n",
    "                        msg=f'you entered {ans} Training will continue to epoch {self.ask_epoch}'\n",
    "                        print(msg) # cyan foreground\n",
    "                        if self.dwell==False:\n",
    "                            lr=float(tf.keras.backend.get_value(self.model.optimizer.lr)) # get the current learning rate\n",
    "                            msg=f'current LR is  {lr:8.6f}  hit enter to keep  this LR or enter a new LR'\n",
    "                            print(msg) # cyan foreground\n",
    "                            ans=input(' ')\n",
    "                            if ans =='':\n",
    "                                msg=f'keeping current LR of {lr:7.5f}'\n",
    "                                print(msg) # cyan foreground\n",
    "                            else:\n",
    "                                new_lr=float(ans)\n",
    "                                tf.keras.backend.set_value(self.model.optimizer.lr, new_lr) # set the learning rate in the optimizer\n",
    "                                msg=f' changing LR to {ans}'\n",
    "                                print(msg) # cyan foreground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Load images from the 'items/' folder\n",
    "temp = np.load('/content/drive/MyDrive/Homeworkâ€™s/public_data.npz', allow_pickle = True)\n",
    "img = temp[\"data\"]\n",
    "label = temp[\"labels\"]\n",
    "  # Normalize image pixel values to a float range [0, 1]\n",
    "img = (img).astype(np.float32)\n",
    "\n",
    "# set 0,1 label\n",
    "for i in range(len(label)):\n",
    "    if(label[i] == 'healthy'):\n",
    "        label[i] = 0\n",
    "    else:\n",
    "        label[i] = 1\n",
    "\n",
    "# cleaning images from trol and shrek\n",
    "ref_img = img[58]\n",
    "ref_img2 = img[2150]\n",
    "c = 0\n",
    "c2 = 0\n",
    "rm_indexes = []\n",
    "rm2_indexes = []\n",
    "for i in range(0, len(img)):\n",
    "    deviation = np.mean(np.abs(ref_img - img[i]))\n",
    "    deviation2 = np.mean(np.abs(ref_img2 - img[i]))\n",
    "    if(deviation == 0.0):\n",
    "        #print(i)\n",
    "        c += 1\n",
    "        rm_indexes.append(i)\n",
    "    elif(deviation2 == 0.0):\n",
    "        c2 += 1\n",
    "        rm2_indexes.append(i)\n",
    "\n",
    "clean_img = np.delete(img, rm_indexes + rm2_indexes, axis=0)\n",
    "clean_label = np.delete(label, rm_indexes + rm2_indexes, axis=0)\n",
    "\n",
    "\n",
    "#DATA AUGMENTATION TO BALANCE CLASSES!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "\n",
    "# Create an instance of ImageDataGenerator\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "#     shear_range=[0.3, 0.7],\n",
    "#     zoom_range=[0.3, 0.9],\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    # brightness_range=[0, 0.7],\n",
    "    fill_mode='reflect',\n",
    "    preprocessing_function = orthogonal_rot\n",
    ")\n",
    "\n",
    "# Reshape the numpy array to fit the requirements of the flow method\n",
    "x = clean_img[clean_label == 1]  # Replace 'your_numpy_array' with your actual numpy array\n",
    "\n",
    "# Create a generator to augment the images\n",
    "augmented_images = []\n",
    "for x_batch in datagen.flow(x, batch_size=1, seed=42, shuffle=False):\n",
    "    augmented_images.append(x_batch[0])\n",
    "    if len(augmented_images) >= 1198:\n",
    "        break\n",
    "\n",
    "# Convert the list of augmented images to a numpy array\n",
    "augmented_images_array = np.array(augmented_images)\n",
    "\n",
    "clean_img = np.append(clean_img, augmented_images_array, axis = 0)\n",
    "clean_label = np.append(clean_label, np.ones(1198))\n",
    "print(clean_img.shape)\n",
    "#!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "\n",
    "\n",
    "# Concatenate 'animals' and 'items' arrays along axis 0\n",
    "X = clean_img\n",
    "# Create labels: 1 for 'animals', 0 for 'items'\n",
    "y = clean_label\n",
    "\n",
    "y = tfk.utils.to_categorical(y, 2) #one hot encodi\n",
    "\n",
    "# Split data into train_val and test sets\n",
    "#X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, random_state=seed, test_size=1000, stratify=np.argmax(y,axis=1))\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, random_state=seed, test_size=.15, stratify=np.argmax(y,axis=1))\n",
    "del X, y, img, clean_img, clean_label, temp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NEW PART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://raw.githubusercontent.com/wangz10/contrastive_loss/master/losses.py\n",
    "!pip install tensorflow_addons\n",
    "import math\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import *\n",
    "from tqdm.notebook import tqdm\n",
    "# from wandb.keras import WandbCallback\n",
    "import tensorflow_datasets as tfds\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import losses\n",
    "import time\n",
    "\n",
    "tf.random.set_seed(666)\n",
    "np.random.seed(666)\n",
    "\n",
    "tfds.disable_progress_bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTO = tf.data.experimental.AUTOTUNE\n",
    "HEIGHT = 96\n",
    "WIDTH = 96\n",
    "\n",
    "yy_train = np.argmax(y_train, axis = -1)\n",
    "yy_val = np.argmax(y_val, axis = -1)\n",
    "train_tf = tf.data.Dataset.from_tensor_slices((X_train, yy_train.astype(int)))#remove astype(int) at the end\n",
    "validation_tf = tf.data.Dataset.from_tensor_slices((X_val, yy_val.astype(int)))\n",
    "\n",
    "IMG_SHAPE = 96\n",
    "BS = 128\n",
    "AUTO = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "# Referred from: https://arxiv.org/pdf/2002.05709.pdf (Appendxi A\n",
    "# corresponding GitHub: https://github.com/google-research/simclr/)\n",
    "# I did not use all the augmentation policies proposed in the above paper\n",
    "\n",
    "@tf.function\n",
    "def custom_augment(image, label):\n",
    "    # Random flips\n",
    "    image = random_apply(tf.image.flip_left_right, image, p=0.4)\n",
    "    image = random_apply(tf.image.flip_up_down, image, p = 0.2)\n",
    "    image = random_apply(tf.image.rot90, image, p = 0.1)\n",
    "    image = random_apply(cut_out, image, p = 0.6)\n",
    "    image = random_apply(aug_shear, image, p = 0.4)\n",
    "    image = random_apply(crop_img, image, p = 0.2)\n",
    "\n",
    "\n",
    "    # Randomly apply transformation (color distortions) with probability p.\n",
    "    # image = random_apply(color_jitter, image, p=0.4)\n",
    "#     image = random_apply(color_drop, image, p=0.2)\n",
    "#     image = random_apply(cacca_su_img, image, p = 0.4)\n",
    "    image = random_apply(tf.image.transpose, image, p = 0.5)\n",
    "    return (image, label)\n",
    "\n",
    "@tf.function\n",
    "def color_jitter(x, s=0.2):\n",
    "    # one can also shuffle the order of following augmentations\n",
    "    # each time they are applied.\n",
    "    x = tf.image.random_brightness(x, max_delta=0.8*s)\n",
    "    x = tf.image.random_contrast(x, lower=1-0.8*s, upper=1+0.8*s)\n",
    "    x = tf.image.random_saturation(x, lower=1-0.8*s, upper=1+0.8*s)\n",
    "    x = tf.image.random_hue(x, max_delta=0.2*s)\n",
    "    x = tf.clip_by_value(x, 0, 1)\n",
    "    return x\n",
    "\n",
    "@tf.function\n",
    "def color_drop(x):\n",
    "    x = tf.image.rgb_to_grayscale(x)\n",
    "    x = tf.tile(x, [1, 1, 3])\n",
    "    return x\n",
    "\n",
    "@tf.function\n",
    "def cut_out(x):\n",
    "  return data_augment_cutout(x)\n",
    "\n",
    "def data_augment_cutout(image, min_mask_size=(int(HEIGHT * .1), int(HEIGHT * .1)),\n",
    "                        max_mask_size=(int(HEIGHT * .125), int(HEIGHT * .125))):\n",
    "    p_cutout = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n",
    "\n",
    "    if p_cutout > .85: # 10~15 cut outs\n",
    "        n_cutout = tf.random.uniform([], 10, 15, dtype=tf.int32)\n",
    "        image = random_cutout(image, HEIGHT, WIDTH,\n",
    "                              min_mask_size=min_mask_size, max_mask_size=max_mask_size, k=n_cutout)\n",
    "    elif p_cutout > .6: # 5~10 cut outs\n",
    "        n_cutout = tf.random.uniform([], 5, 10, dtype=tf.int32)\n",
    "        image = random_cutout(image, HEIGHT, WIDTH,\n",
    "                              min_mask_size=min_mask_size, max_mask_size=max_mask_size, k=n_cutout)\n",
    "    elif p_cutout > .25: # 2~5 cut outs\n",
    "        n_cutout = tf.random.uniform([], 2, 5, dtype=tf.int32)\n",
    "        image = random_cutout(image, HEIGHT, WIDTH,\n",
    "                              min_mask_size=min_mask_size, max_mask_size=max_mask_size, k=n_cutout)\n",
    "    else: # 1 cut out\n",
    "        image = random_cutout(image, HEIGHT, WIDTH,\n",
    "                              min_mask_size=min_mask_size, max_mask_size=max_mask_size, k=1)\n",
    "\n",
    "    return image\n",
    "def random_cutout(image, height, width, channels=3, min_mask_size=(10, 10), max_mask_size=(80, 80), k=1):\n",
    "    assert height > min_mask_size[0]\n",
    "    assert width > min_mask_size[1]\n",
    "    assert height > max_mask_size[0]\n",
    "    assert width > max_mask_size[1]\n",
    "    for i in range(k):\n",
    "      mask_height = tf.random.uniform(shape=[], minval=min_mask_size[0], maxval=max_mask_size[0], dtype=tf.int32)\n",
    "      mask_width = tf.random.uniform(shape=[], minval=min_mask_size[1], maxval=max_mask_size[1], dtype=tf.int32)\n",
    "\n",
    "      pad_h = height - mask_height\n",
    "      pad_top = tf.random.uniform(shape=[], minval=0, maxval=pad_h, dtype=tf.int32)\n",
    "      pad_bottom = pad_h - pad_top\n",
    "\n",
    "      pad_w = width - mask_width\n",
    "      pad_left = tf.random.uniform(shape=[], minval=0, maxval=pad_w, dtype=tf.int32)\n",
    "      pad_right = pad_w - pad_left\n",
    "\n",
    "      cutout_area = tf.zeros(shape=[mask_height, mask_width, channels], dtype=tf.uint8)\n",
    "\n",
    "      cutout_mask = tf.pad([cutout_area], [[0,0],[pad_top, pad_bottom], [pad_left, pad_right], [0,0]], constant_values=1)\n",
    "      cutout_mask = tf.squeeze(cutout_mask, axis=0)\n",
    "      image = tf.multiply(tf.cast(image, tf.float32), tf.cast(cutout_mask, tf.float32))\n",
    "\n",
    "    return image\n",
    "\n",
    "@tf.function\n",
    "def aug_shear(x):\n",
    "  p_shear = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n",
    "  if p_shear > .5:\n",
    "      x = transform_shear(x, HEIGHT, shear=20.)\n",
    "  else:\n",
    "      x = transform_shear(x, HEIGHT, shear=-20.)\n",
    "  return x\n",
    "\n",
    "def transform_shear(image, height, shear):\n",
    "    # input image - is one image of size [dim,dim,3] not a batch of [b,dim,dim,3]\n",
    "    # output - image randomly sheared\n",
    "    DIM = height\n",
    "    XDIM = DIM%2 #fix for size 331\n",
    "\n",
    "    shear = shear * tf.random.uniform([1],dtype='float32')\n",
    "    shear = math.pi * shear / 180.\n",
    "\n",
    "    # SHEAR MATRIX\n",
    "    one = tf.constant([1],dtype='float32')\n",
    "    zero = tf.constant([0],dtype='float32')\n",
    "    c2 = tf.math.cos(shear)\n",
    "    s2 = tf.math.sin(shear)\n",
    "    shear_matrix = tf.reshape(tf.concat([one,s2,zero, zero,c2,zero, zero,zero,one],axis=0),[3,3])\n",
    "\n",
    "    # LIST DESTINATION PIXEL INDICES\n",
    "    x = tf.repeat( tf.range(DIM//2,-DIM//2,-1), DIM )\n",
    "    y = tf.tile( tf.range(-DIM//2,DIM//2),[DIM] )\n",
    "    z = tf.ones([DIM*DIM],dtype='int32')\n",
    "    idx = tf.stack( [x,y,z] )\n",
    "\n",
    "    # ROTATE DESTINATION PIXELS ONTO ORIGIN PIXELS\n",
    "    idx2 = K.dot(shear_matrix,tf.cast(idx,dtype='float32'))\n",
    "    idx2 = K.cast(idx2,dtype='int32')\n",
    "    idx2 = K.clip(idx2,-DIM//2+XDIM+1,DIM//2)\n",
    "\n",
    "    # FIND ORIGIN PIXEL VALUES\n",
    "    idx3 = tf.stack( [DIM//2-idx2[0,], DIM//2-1+idx2[1,]] )\n",
    "    d = tf.gather_nd(image, tf.transpose(idx3))\n",
    "\n",
    "    return tf.reshape(d,[DIM,DIM,3])\n",
    "\n",
    "@tf.function\n",
    "def crop_img(x):\n",
    "  p_crop = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n",
    "  if p_crop > .6:\n",
    "    if p_crop > .9:\n",
    "        x = tf.image.central_crop(x, central_fraction=.5)\n",
    "    elif p_crop > .8:\n",
    "        x = tf.image.central_crop(x, central_fraction=.6)\n",
    "    elif p_crop > .7:\n",
    "        x = tf.image.central_crop(x, central_fraction=.7)\n",
    "    else:\n",
    "        x = tf.image.central_crop(x, central_fraction=.8)\n",
    "  elif p_crop > .3:\n",
    "    crop_size = tf.random.uniform([], int(HEIGHT*.6), HEIGHT, dtype=tf.int32)\n",
    "    x = tf.image.random_crop(x, size=[crop_size, crop_size, 3])\n",
    "  x = tf.image.resize(x, size=[HEIGHT, WIDTH])\n",
    "  return x\n",
    "\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def random_apply(func, x, p):\n",
    "    return tf.cond(\n",
    "        tf.less(tf.random.uniform([], minval=0, maxval=1, dtype=tf.float32),\n",
    "                tf.cast(p, tf.float32)),\n",
    "        lambda: func(x),\n",
    "        lambda: x)\n",
    "\n",
    "# # @tf.function\n",
    "# def cacca_su_img(imageee):\n",
    "#     imagee = 255*imageee.numpy()\n",
    "#     lista = [20, 25, 30, 35]\n",
    "#     l = random.choice(lista)\n",
    "#     box = np.zeros(l**2).reshape(l, l)\n",
    "#     xx, yy = np.random.randint(0,95-l, size=2)\n",
    "#     for i in range(3):\n",
    "#         imagee[xx:xx+l, yy:yy+l, i] = box\n",
    "\n",
    "#     imagee = tf.convert_to_tensor(imagee)\n",
    "\n",
    "#     return imagee/255\n",
    "\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def preprocess_image(image, label):\n",
    "  # image = image/255\n",
    "  image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "  #     image = tf.image.resize(image, (IMG_SHAPE, IMG_SHAPE))\n",
    "  image = image/255\n",
    "  return (image, label)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def preprocess_image_class(image, label):\n",
    "  image = image/255\n",
    "  label = tf.one_hot()\n",
    "  return (image, label)\n",
    "\n",
    "train_tf = (\n",
    "    train_tf\n",
    "    .map(preprocess_image, num_parallel_calls=AUTO)\n",
    "    .shuffle(100)\n",
    "    .map(custom_augment, num_parallel_calls=AUTO)\n",
    "    .batch(BS)\n",
    "    .prefetch(AUTO)\n",
    ")\n",
    "\n",
    "validation_tf = (\n",
    "    validation_tf\n",
    "    .map(preprocess_image, num_parallel_calls=AUTO)\n",
    "    .shuffle(100)\n",
    "    .batch(32)#BS\n",
    "    .prefetch(AUTO)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting the augmented images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_batch, label_batch = next(iter(train_tf))\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for n in range(25):\n",
    "    ax = plt.subplot(5, 5, n+1)\n",
    "    plt.imshow(image_batch[n])\n",
    "    plt.title(label_batch[n].numpy())\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Convnext again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tf = (train_tf.map(lambda x, y: (x, tf.one_hot(y, depth =2)))) #let's go back to categorical values\n",
    "validation_tf = (validation_tf.map(lambda x, y: (x, tf.one_hot(y, depth = 2))))\n",
    "\n",
    "from tensorflow.keras.layers import Dense, Activation,Dropout,Conv2D, MaxPooling2D,BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam, Adamax\n",
    "from tensorflow.keras.metrics import categorical_crossentropy\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.models import Model\n",
    "convlarge = tf.keras.applications.ConvNeXtBase(\n",
    "    include_top=False,\n",
    "    include_preprocessing=True,\n",
    "    weights=\"imagenet\",\n",
    "    input_tensor=None,\n",
    "    input_shape= (96,96, 3),\n",
    "    pooling=\"max\",\n",
    "    classes=2,\n",
    "    classifier_activation=\"softmax\",\n",
    ")\n",
    "\n",
    "convlarge.trainable = False\n",
    "\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "# Build the neural network layer by layer\n",
    "inputs = tfkl.Input(shape=(96, 96, 3))\n",
    "# x = img_augmentation(inputs)\n",
    "x = convlarge(inputs*255)\n",
    "# x = layers.GlobalAveragePooling2D(name = \"gap\")(x)\n",
    "x=BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, name = \"batch\")(x)\n",
    "\n",
    "\n",
    "x = layers.Dense(256, kernel_regularizer = regularizers.l2(l = 0.016),activity_regularizer=regularizers.l1(0.006),\n",
    "                    bias_regularizer=regularizers.l1(0.006) ,activation='relu')(x)\n",
    "# x = layers.Dense(256, kernel_initializer=tf.keras.initializers.HeUniform(seed=42))(x)\n",
    "x = layers.BatchNormalization(name = \"batch2\")(x)\n",
    "x = layers.Dropout(0.3, seed = 42, name = \"dropout\")(x)\n",
    "\n",
    "x = layers.Dense(128, kernel_regularizer = regularizers.l2(l = 0.016),activity_regularizer=regularizers.l1(0.006),\n",
    "                    bias_regularizer=regularizers.l1(0.006) ,activation='relu')(x)\n",
    "x = layers.BatchNormalization(name = \"batch3\")(x)\n",
    "x = layers.Dropout(0.3, seed = 42, name = \"dropout2\")(x)\n",
    "\n",
    "outputs = tfkl.Dense(units=2, activation='softmax',name='Output2')(x)  #you cannnot use softmax with only one neuron since it normalizes over the output neurons\n",
    "model = tfk.Model(inputs, outputs)\n",
    "model.compile(loss=tfk.losses.CategoricalCrossentropy(), optimizer=tfk.optimizers.Adamax(learning_rate=0.01), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=100\n",
    "ask_epoch=20\n",
    "ask=LR_ASK(model, epochs,  ask_epoch)\n",
    "callbacks=[ask]\n",
    "\n",
    "history=model.fit(x=train_tf,  epochs=epochs, verbose=1, callbacks=callbacks,  validation_data=validation_tf,\n",
    "               validation_steps=None,  shuffle=False,  initial_epoch=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FINE TUNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
